# ========================================
# PROVIDER SELECTION
# ========================================
PROVIDER=ollama

# ========================================
# CORS Configuration
# ========================================
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# ========================================
# LOCAL OLLAMA (free)
# ========================================
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TIMEOUT=120
# ⬆️ Timeout in seconds (default: 120)
# First request can be slow (loading model into RAM)
# Increase if you get timeouts: 180 or 240

# TIPS TO SPEED UP:
# 1. Use smaller model: ollama pull llama3.2:1b
# 2. First request is always slow (model loads)
# 3. Keep Ollama running between requests
# 4. Ensure you have 4GB+ RAM available

# ========================================
# OPENAI (paid)
# ========================================
# PROVIDER=openai
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini

# ========================================
# REPLICATE (paid - for llama-3.1-70B)
# ========================================
# PROVIDER=replicate
# REPLICATE_API_TOKEN=r8_...

# ========================================
# HUGGINGFACE INFERENCE API (free tier)
# ========================================
# PROVIDER=hf_inference
# HF_API_KEY=hf_...
# HF_MODEL=meta-llama/Llama-3.2-3B-Instruct

# ========================================
# RAG/Vector Search (optional)
# ========================================
# ENABLE_RAG=false